{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer   False\n",
      "1 Conv2D   True\n",
      "2 Conv2D   True\n",
      "3 MaxPooling2D   True\n",
      "4 Conv2D   True\n",
      "5 Conv2D   True\n",
      "6 MaxPooling2D   True\n",
      "7 Conv2D   True\n",
      "8 Conv2D   True\n",
      "9 Conv2D   True\n",
      "10 MaxPooling2D   True\n",
      "11 Conv2D   True\n",
      "12 Conv2D   True\n",
      "13 Conv2D   True\n",
      "14 MaxPooling2D   True\n",
      "15 Conv2D   True\n",
      "16 Conv2D   True\n",
      "17 Conv2D   True\n",
      "18 MaxPooling2D   True\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16 \n",
    "\n",
    "img_rows = 224\n",
    "img_cols = 224\n",
    "\n",
    "model = VGG16( weights = 'imagenet', \n",
    "               include_top = False, \n",
    "               input_shape = (img_rows, img_cols, 3) )\n",
    "\n",
    "\n",
    "for (i,layer) in enumerate(model.layers):\n",
    "    print(str(i)+\" \"+layer.__class__.__name__,\" \",layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer   False\n",
      "1 Conv2D   False\n",
      "2 Conv2D   False\n",
      "3 MaxPooling2D   False\n",
      "4 Conv2D   False\n",
      "5 Conv2D   False\n",
      "6 MaxPooling2D   False\n",
      "7 Conv2D   False\n",
      "8 Conv2D   False\n",
      "9 Conv2D   False\n",
      "10 MaxPooling2D   False\n",
      "11 Conv2D   False\n",
      "12 Conv2D   False\n",
      "13 Conv2D   False\n",
      "14 MaxPooling2D   False\n",
      "15 Conv2D   False\n",
      "16 Conv2D   False\n",
      "17 Conv2D   False\n",
      "18 MaxPooling2D   False\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for (i,layer) in enumerate(model.layers):\n",
    "    print(str(i)+\" \"+layer.__class__.__name__,\" \",layer.trainable)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layers(bottom_model, num_classes):\n",
    "    \"\"\"creates the top or head of the model that will be \n",
    "    placed ontop of the bottom layers\"\"\"\n",
    "\n",
    "    top_model = bottom_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(512,activation='relu')(top_model)\n",
    "    top_model = Dense(256,activation='relu')(top_model)\n",
    "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1d24df16348>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d2567acf08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d2567c9b88>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1d25681dd08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d25681b2c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d25681ffc8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1d256825488>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d256825208>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d25682cf48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d256839ec8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1d256840a48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d2568401c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d256849d88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d25684a348>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1d25685ae48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d25685ab48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d256863648>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d25686ac48>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1d256874ac8>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 15,897,413\n",
      "Trainable params: 1,182,725\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "# Set our class number to 5\n",
    "num_classes = 5\n",
    "\n",
    "FC_Head = add_layers(model, num_classes)\n",
    "\n",
    "model = Model(inputs = model.input, outputs = FC_Head)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1d24df16348>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d2567acf08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d2567c9b88>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1d25681dd08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d25681b2c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d25681ffc8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1d256825488>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d256825208>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d25682cf48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d256839ec8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1d256840a48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d2568401c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d256849d88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d25684a348>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1d25685ae48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d25685ab48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d256863648>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d25686ac48>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1d256874ac8>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x1d2568abb48>,\n",
       " <keras.layers.core.Dense at 0x1d2568abe08>,\n",
       " <keras.layers.core.Dense at 0x1d256898388>,\n",
       " <keras.layers.core.Dense at 0x1d2568b9fc8>,\n",
       " <keras.layers.core.Dense at 0x1d2568bed08>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 104 images belonging to 5 classes.\n",
      "Found 13 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = 'train/'\n",
    "validation_data_dir = 'test/'\n",
    "\n",
    "# Let's use some data augmentaiton \n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale = 1./255,\n",
    "      rotation_range = 45,\n",
    "      width_shift_range = 0.3,\n",
    "      height_shift_range = 0.3,\n",
    "      horizontal_flip = True,\n",
    "      fill_mode = 'nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "batch_size = 32    \n",
    "    \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size = (img_rows, img_cols),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'categorical')\n",
    " \n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size = (img_rows, img_cols),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"celebrities.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(lr = 0.001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 62s 6s/step - loss: 2.2277 - accuracy: 0.1912 - val_loss: 1.5026 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.50257, saving model to celebrities.h5\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 58s 6s/step - loss: 1.6268 - accuracy: 0.2500 - val_loss: 1.5095 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.50257\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 57s 6s/step - loss: 1.5451 - accuracy: 0.3589 - val_loss: 1.3840 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.50257 to 1.38397, saving model to celebrities.h5\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 67s 7s/step - loss: 1.5197 - accuracy: 0.3529 - val_loss: 1.3291 - val_accuracy: 0.4615\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.38397 to 1.32908, saving model to celebrities.h5\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 57s 6s/step - loss: 1.3890 - accuracy: 0.3952 - val_loss: 1.1980 - val_accuracy: 0.4615\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.32908 to 1.19802, saving model to celebrities.h5\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 64s 6s/step - loss: 1.3975 - accuracy: 0.4743 - val_loss: 1.2857 - val_accuracy: 0.5385\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.19802\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 59s 6s/step - loss: 1.1365 - accuracy: 0.5161 - val_loss: 1.1144 - val_accuracy: 0.5385\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.19802 to 1.11439, saving model to celebrities.h5\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 65s 7s/step - loss: 1.2318 - accuracy: 0.5147 - val_loss: 1.2915 - val_accuracy: 0.4615\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.11439\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 61s 6s/step - loss: 1.0052 - accuracy: 0.5956 - val_loss: 1.0245 - val_accuracy: 0.4615\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.11439 to 1.02449, saving model to celebrities.h5\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 60s 6s/step - loss: 0.9652 - accuracy: 0.6129 - val_loss: 1.4847 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.02449\n"
     ]
    }
   ],
   "source": [
    "# Enter the number of training and validation samples here\n",
    "nb_train_samples = 104\n",
    "nb_validation_samples = 13\n",
    "\n",
    "# We only train 10 EPOCHS \n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "classifier = load_model('celebrities.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "celebrities_dict = {\"[0]\": 'ben_afflek', \n",
    "                    \"[1]\": 'elton_john',\n",
    "                    \"[2]\": 'jerry_seinfeld',\n",
    "                    \"[3]\": 'madonna',\n",
    "                    \"[4]\": 'mindy_kaling'}\n",
    "\n",
    "celebrities_dict_n = {\"n0\": 'ben_afflek', \n",
    "                      \"n1\": 'elton_john',\n",
    "                      \"n2\": 'jerry_seinfeld',\n",
    "                      \"n3\": 'madonna',\n",
    "                      \"n4\": 'mindy_kaling'}\n",
    "\n",
    "def draw_test(name, pred, im):\n",
    "    celebrity = celebrities_dict[str(pred)]\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, celebrity, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage(path):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(path_class)\n",
    "    #print(\"Class - \" + celebrities_dict_n[path_class])\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elton_john\n",
      "jerry_seinfeld\n",
      "mindy_kaling\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,3):\n",
    "    input_im = getRandomImage(\"test/\")\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    \n",
    "    # Show image with predicted class\n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
