{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer   False\n",
      "1 Conv2D   True\n",
      "2 Conv2D   True\n",
      "3 MaxPooling2D   True\n",
      "4 Conv2D   True\n",
      "5 Conv2D   True\n",
      "6 MaxPooling2D   True\n",
      "7 Conv2D   True\n",
      "8 Conv2D   True\n",
      "9 Conv2D   True\n",
      "10 MaxPooling2D   True\n",
      "11 Conv2D   True\n",
      "12 Conv2D   True\n",
      "13 Conv2D   True\n",
      "14 MaxPooling2D   True\n",
      "15 Conv2D   True\n",
      "16 Conv2D   True\n",
      "17 Conv2D   True\n",
      "18 MaxPooling2D   True\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16 \n",
    "\n",
    "img_rows = 224\n",
    "img_cols = 224\n",
    "\n",
    "model = VGG16( weights = 'imagenet', \n",
    "               include_top = False, \n",
    "               input_shape = (img_rows, img_cols, 3) )\n",
    "\n",
    "\n",
    "for (i,layer) in enumerate(model.layers):\n",
    "    print(str(i)+\" \"+layer.__class__.__name__,\" \",layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer   False\n",
      "1 Conv2D   False\n",
      "2 Conv2D   False\n",
      "3 MaxPooling2D   False\n",
      "4 Conv2D   False\n",
      "5 Conv2D   False\n",
      "6 MaxPooling2D   False\n",
      "7 Conv2D   False\n",
      "8 Conv2D   False\n",
      "9 Conv2D   False\n",
      "10 MaxPooling2D   False\n",
      "11 Conv2D   False\n",
      "12 Conv2D   False\n",
      "13 Conv2D   False\n",
      "14 MaxPooling2D   False\n",
      "15 Conv2D   False\n",
      "16 Conv2D   False\n",
      "17 Conv2D   False\n",
      "18 MaxPooling2D   False\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for (i,layer) in enumerate(model.layers):\n",
    "    print(str(i)+\" \"+layer.__class__.__name__,\" \",layer.trainable)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layers(bottom_model, num_classes):\n",
    "    \"\"\"creates the top or head of the model that will be \n",
    "    placed ontop of the bottom layers\"\"\"\n",
    "\n",
    "    top_model = bottom_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(512,activation='relu')(top_model)\n",
    "    top_model = Dense(256,activation='relu')(top_model)\n",
    "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1ed17578288>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fe27d08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fe27dc8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1ed1fe8ecc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fe8ee08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fe9fe08>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1ed1fea2ec8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fea2988>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1feaee88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1feb7508>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1ed1febef88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1febe048>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fec76c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fed1c88>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1ed1fed9ac8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fed9888>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fee2988>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fee4308>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1ed1feed7c8>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 15,897,413\n",
      "Trainable params: 1,182,725\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "# Set our class number to 5\n",
    "num_classes = 5\n",
    "\n",
    "FC_Head = add_layers(model, num_classes)\n",
    "\n",
    "model = Model(inputs = model.input, outputs = FC_Head)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1ed17578288>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fe27d08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fe27dc8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1ed1fe8ecc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fe8ee08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fe9fe08>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1ed1fea2ec8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fea2988>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1feaee88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1feb7508>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1ed1febef88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1febe048>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fec76c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fed1c88>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1ed1fed9ac8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fed9888>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fee2988>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1ed1fee4308>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1ed1feed7c8>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x1ed1ff1fa88>,\n",
       " <keras.layers.core.Dense at 0x1ed1ff1fd48>,\n",
       " <keras.layers.core.Dense at 0x1ed1ff2bc08>,\n",
       " <keras.layers.core.Dense at 0x1ed1ff14f48>,\n",
       " <keras.layers.core.Dense at 0x1ed2006ca88>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 104 images belonging to 5 classes.\n",
      "Found 13 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = 'train/'\n",
    "validation_data_dir = 'test/'\n",
    "\n",
    "# Let's use some data augmentaiton \n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale = 1./255,\n",
    "      rotation_range = 45,\n",
    "      width_shift_range = 0.3,\n",
    "      height_shift_range = 0.3,\n",
    "      horizontal_flip = True,\n",
    "      fill_mode = 'nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "batch_size = 32    \n",
    "    \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size = (img_rows, img_cols),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'categorical')\n",
    " \n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size = (img_rows, img_cols),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"celebrities.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(lr = 0.001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 76s 8s/step - loss: 1.9953 - accuracy: 0.1544 - val_loss: 1.6648 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.66485, saving model to celebrities.h5\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 65s 7s/step - loss: 1.6089 - accuracy: 0.2581 - val_loss: 1.6397 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.66485 to 1.63965, saving model to celebrities.h5\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 59s 6s/step - loss: 1.5372 - accuracy: 0.2782 - val_loss: 1.5223 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.63965 to 1.52228, saving model to celebrities.h5\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 65s 7s/step - loss: 1.4535 - accuracy: 0.3493 - val_loss: 1.3626 - val_accuracy: 0.5385\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.52228 to 1.36257, saving model to celebrities.h5\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 65s 7s/step - loss: 1.5221 - accuracy: 0.4435 - val_loss: 1.3275 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.36257 to 1.32751, saving model to celebrities.h5\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 80s 8s/step - loss: 1.1405 - accuracy: 0.5074 - val_loss: 1.5676 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.32751\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 67s 7s/step - loss: 1.4290 - accuracy: 0.3911 - val_loss: 1.1811 - val_accuracy: 0.5385\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.32751 to 1.18113, saving model to celebrities.h5\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 74s 7s/step - loss: 1.1510 - accuracy: 0.5809 - val_loss: 0.9331 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.18113 to 0.93314, saving model to celebrities.h5\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.9817 - accuracy: 0.6250 - val_loss: 0.9401 - val_accuracy: 0.5385\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.93314\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.9401 - accuracy: 0.6728 - val_loss: 0.9234 - val_accuracy: 0.5385\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.93314 to 0.92340, saving model to celebrities.h5\n"
     ]
    }
   ],
   "source": [
    "# Enter the number of training and validation samples here\n",
    "nb_train_samples = 104\n",
    "nb_validation_samples = 13\n",
    "\n",
    "# We only train 10 EPOCHS \n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "classifier = load_model('celebrities.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "celebrities_dict = {\"[0]\": 'ben_afflek', \n",
    "                    \"[1]\": 'elton_john',\n",
    "                    \"[2]\": 'jerry_seinfeld',\n",
    "                    \"[3]\": 'madonna',\n",
    "                    \"[4]\": 'mindy_kaling'}\n",
    "\n",
    "celebrities_dict_n = {\"n0\": 'ben_afflek', \n",
    "                      \"n1\": 'elton_john',\n",
    "                      \"n2\": 'jerry_seinfeld',\n",
    "                      \"n3\": 'madonna',\n",
    "                      \"n4\": 'mindy_kaling'}\n",
    "\n",
    "def draw_test(name, pred, im):\n",
    "    celebrity = celebrities_dict[str(pred)]\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, celebrity, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage(path):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(path_class)\n",
    "    #print(\"Class - \" + celebrities_dict_n[path_class])\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mindy_kaling\n",
      "ben_afflek\n",
      "ben_afflek\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,3):\n",
    "    input_im = getRandomImage(\"test/\")\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    \n",
    "    # Show image with predicted class\n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
